{
    "title": "LLM Dataset Processor",
    "description": "Choose specific dataset to process, select LLM, provide API token and craft your prompt template. We recommend testing your prompt first by enabling `Test Prompt Mode`. ",
    "type": "object",
    "schemaVersion": 1,
    "required": [
        "llmProviderApiKey",
        "prompt",
        "model",
        "temperature",
        "maxTokens"
    ],
    "properties": {
        "inputDatasetId": {
            "type": "string",
            "title": "Input Dataset ID",
            "description": "The ID of the dataset to process.",
            "resourceType": "dataset"
        },
        "model": {
            "type": "string",
            "title": "Large Language Model",
            "description": "The LLM to use for processing. Each model has different capabilities and pricing. GPT-4o-mini and Claude 3.5 Haiku are recommended for cost-effective processing, while models like Claude 3 Opus or GPT-4o offer higher quality but at a higher cost.",
            "editor": "select",
            "enumTitles": ["GPT-4o mini (Recommended)", "GPT-4o", "Claude 3.5 Haiku (Recommended)", "Claude 3.5 Sonnet", "Claude 3 Opus", "Gemini 1.5 Flash", "Gemini 1.5 Flash-8B (Recommended)" ,"Gemini 1.5 Pro"],
            "enum": ["gpt-4o-mini", "gpt-4o", "claude-3-5-haiku-latest", "claude-3-5-sonnet-latest", "claude-3-opus-latest", "gemini-1.5-flash", "gemini-1.5-flash-8b", "gemini-1.5-pro"]
        },
        "llmProviderApiKey": {
            "type": "string",
            "title": "LLM Provider API Key",
            "editor": "textfield",
            "description": "Your API key for the LLM Provider (e.g., OpenAI).",
            "isSecret": true
        },
        "temperature": {
            "type": "string",
            "title": "Temperature",
            "editor": "textfield",
            "description": "Sampling temperature for the LLM API (controls randomness). We recommend using a value closer to 0 for exact results. In case of more 'creative' results, we recommend to use a value closer to 1.",
            "default": "0.1"
        },
        "multipleColumns": {
            "type": "boolean",
            "title": "Multiple columns in output",
            "description": "When enabled, instructs the LLM to return responses as JSON objects, creating multiple columns in the output dataset. The columns need to be named and described in the prompt. If disabled, responses are stored in a single `llmresponse` column.",
            "default": false
        },
        "prompt": {
            "type": "string",
            "title": "Prompt Template",
            "description": "The prompt template to use for processing. You can use ${fieldName} placeholders to reference fields from the input dataset.",
            "editor": "textarea",
            "minLength": 1,
            "prefill": "Summarize this text: ${text}"
        },
        "skipItemIfEmpty": {
            "type": "boolean",
            "title": "Skip item if one or more ${fields} are empty",
            "description": "When enabled, items will be skipped if any ${field} referenced in the prompt is empty, null, undefined, or contains only whitespace. This helps prevent processing incomplete data.",
            "default": true
        },
        "maxTokens": {
            "type": "integer",
            "title": "Max Tokens",
            "editor": "number",
            "description": "Maximum number of tokens in the LLM API response for each item.",
            "default": 300
        },
        "testPrompt": {
            "type": "boolean",
            "title": "Test Prompt Mode",
            "description": "Test mode that processes only a limited number of items (defined by `testItemsCount`). Use this to validate your prompt and configuration before running on the full dataset. We highly recommend enabling this option first to validate your prompt because of ambiguity of the LLM responses.",
            "default": true
        },
        "testItemsCount": {
            "type": "integer",
            "title": "Test Items Count",
            "description": "Number of items to process when `Test Prompt Mode` is enabled.",
            "default": 3,
            "minimum": 1
        },
        "preprocessingFunction": {
            "title": "Preprocessing function",
            "type": "string",
            "description": "Function to transform item before they are put into the promp.",
            "editor": "javascript",
            "prefill": "(item) => {\n    return item;\n}",
            "sectionCaption": "Transforming functions",
            "sectionDescription": "Optionally transform the data. The function is called for each item. This is needed to use for fields that are array.\n\nExample:\n```js\n(item) => {\n    item.joinedReviewsTexts = item.reviews.reduce((joinedText, review) => {\n        return joinedText + '\\n' + review.text;\n    })\n    return item;\n}\n```\n\nThen, you can use `${joinedReviewsTexts}` in your prompt."
        }
    }
}
